{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log into DOs' datasites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from syft_rds.orchestra import setup_rds_server\n",
    "\n",
    "DS = \"ds@openmined.org\"\n",
    "DO1 = \"do1@openmined.org\"\n",
    "DO2 = \"do2@openmined.org\"\n",
    "\n",
    "ds_stack = setup_rds_server(email=DS, key=\"flwr\", root_dir=Path(\".\"))\n",
    "\n",
    "do_client_1 = ds_stack.init_session(host=DO1)\n",
    "print(\"Logged into: \", do_client_1.host)\n",
    "\n",
    "do_client_2 = ds_stack.init_session(host=DO2)\n",
    "print(\"Logged into: \", do_client_2.host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect DOs' Mock Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYFTBOX_DATASET_NAME = \"pima-indians-diabetes-database\"\n",
    "\n",
    "dataset1 = do_client_1.dataset.get(name=SYFTBOX_DATASET_NAME)\n",
    "dataset1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = do_client_2.dataset.get(name=SYFTBOX_DATASET_NAME)\n",
    "dataset2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS does some data analytics on mock datasets\n",
    "\n",
    "For each client:\n",
    "1. Concat the dataframes in `train.csv` and `mock.csv`\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1_train = pd.read_csv(dataset1.get_mock_path() / \"train.csv\")\n",
    "df1_test = pd.read_csv(dataset1.get_mock_path() / \"test.csv\")\n",
    "\n",
    "df2_train = pd.read_csv(dataset2.get_mock_path() / \"train.csv\")\n",
    "df2_test = pd.read_csv(dataset2.get_mock_path() / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.concat([df1_train, df1_test, df2_train, df2_test], ignore_index=True)\n",
    "pima.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_col_idx = pima.columns\n",
    "pima_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nutritional status column\n",
    "\n",
    "Nutritional_status = pd.Series([])\n",
    "\n",
    "for i in range(len(pima)):\n",
    "    if pima[\"BMI\"][i] == 0.0:\n",
    "        Nutritional_status[i] = \"NA\"\n",
    "\n",
    "    elif pima[\"BMI\"][i] < 18.5:\n",
    "        Nutritional_status[i] = \"Underweight\"\n",
    "\n",
    "    elif pima[\"BMI\"][i] < 25:\n",
    "        Nutritional_status[i] = \"Normal\"\n",
    "\n",
    "    elif pima[\"BMI\"][i] >= 25 and pima[\"BMI\"][i] < 30:\n",
    "        Nutritional_status[i] = \"Overweight\"\n",
    "\n",
    "    elif pima[\"BMI\"][i] >= 30:\n",
    "        Nutritional_status[i] = \"Obese\"\n",
    "\n",
    "    else:\n",
    "        Nutritional_status[i] = pima[\"BMI\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.insert(6, \"Nutritional Status\", Nutritional_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima[\"Nutritional Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing `syft_flwr` project code\n",
    "\n",
    "```bash\n",
    "fed-analytics-diabetes/\n",
    "├── fed_analytics_diabetes/\n",
    "│   ├── __init__.py\n",
    "│   ├── client_app.py\n",
    "│   └── server_app.py\n",
    "├── pyproject.toml\n",
    "└── README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SYFT_FLWR_PROJECT_DIR = Path(\"./fed-analytics-diabetes\")\n",
    "assert SYFT_FLWR_PROJECT_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `flwr` simulation\n",
    "\n",
    "After preparing `syft_flwr` code, DS runs `flwr run` to make sure that it's compatible with Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_SIMULATION = 1\n",
    "\n",
    "if RUN_SIMULATION:\n",
    "    !flwr run {SYFT_FLWR_PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping the `flwr` project\n",
    "DS runs `syft_flwr.boostrap` to turn a `flwr` project into a `syft_flwr` project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft_flwr\n",
    "\n",
    "try:\n",
    "    !rm -rf {SYFT_FLWR_PROJECT_DIR / \"main.py\"}\n",
    "    syft_flwr.bootstrap(SYFT_FLWR_PROJECT_DIR, aggregator=DS, datasites=[DO1, DO2])\n",
    "    print(\"Bootstrapped project successfully ✅\")\n",
    "except Exception as e:\n",
    "    print(f\"Bootstrapped project failed with error: '{e}' ❌\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS runs `syft_flwr` simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SIMULATION:\n",
    "    syft_flwr.run(\n",
    "        SYFT_FLWR_PROJECT_DIR, [dataset1.get_mock_path(), dataset2.get_mock_path()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS submits jobs to DOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {SYFT_FLWR_PROJECT_DIR / \"pandas_example\" / \"__pycache__/\"}\n",
    "!rm -rf {SYFT_FLWR_PROJECT_DIR / \"simulation_logs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs submission\n",
    "datasites = [do_client_1, do_client_2]\n",
    "\n",
    "for client in datasites:\n",
    "    job = client.jobs.submit(\n",
    "        name=\"iris_fed_analytics\",\n",
    "        description=\"Syft Flower Federated Analytics on the Iris Dataset\",\n",
    "        user_code_path=SYFT_FLWR_PROJECT_DIR,\n",
    "        dataset_name=SYFTBOX_DATASET_NAME,\n",
    "        tags=[\"federated\", \"analytics\", \"syft_flwr\", \"flwr\"],\n",
    "        entrypoint=\"main.py\",\n",
    "    )\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS runs FL server code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SYFTBOX_CLIENT_CONFIG_PATH\"] = str(ds_stack.client.config_path)\n",
    "os.environ[\"LOGURU_LEVEL\"] = \"DEBUG\"\n",
    "\n",
    "!uv run {str(SYFT_FLWR_PROJECT_DIR / \"main.py\")} --active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
